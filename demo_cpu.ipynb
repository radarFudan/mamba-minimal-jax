{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu only\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shida/anaconda3/envs/S5Again/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2023-12-31 13:12:25.091185: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from model_cpu import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# One of:\n",
    "#     'state-spaces/mamba-2.8b-slimpj'\n",
    "#     'state-spaces/mamba-2.8b'\n",
    "#     'state-spaces/mamba-1.4b'\n",
    "#     'state-spaces/mamba-790m'\n",
    "#     'state-spaces/mamba-370m'\n",
    "#     'state-spaces/mamba-130m'\n",
    "pretrained_model_name = 'state-spaces/mamba-370m'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')\n",
    "model, params = Mamba.from_pretrained(pretrained_model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "\n",
    "def jax_generate(model,\n",
    "                 params, \n",
    "                 tokenizer,\n",
    "                 prompt: str,\n",
    "                 n_tokens_to_gen: int = 128,\n",
    "                 sample: bool = True,\n",
    "                 top_k: int = 40,\n",
    "                 rng = jax.random.PRNGKey(7),\n",
    "                 ):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids # In pytorch format\n",
    "    input_ids = np.array(input_ids.numpy()) # In jax format\n",
    "\n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        indices_to_input = input_ids\n",
    "        next_token_logits = model.apply(params, indices_to_input)[:, -1]\n",
    "\n",
    "        probs = jax.nn.softmax(next_token_logits, axis=-1)\n",
    "\n",
    "        if top_k is not None:\n",
    "            (values, indices) = jax.lax.top_k(probs, k=top_k)\n",
    "            mask = probs < np.expand_dims(values[:, -1], axis=1)\n",
    "            probs = np.where(mask, 0.0, probs)\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "        if sample:\n",
    "            # TODO, might not be 100% correct. \n",
    "            rng, subrng = jax.random.split(rng)\n",
    "            next_indices = jax.random.categorical(subrng, jax.nn.log_softmax(probs), 1, shape=probs.shape[:-1]+(1,))\n",
    "        else:\n",
    "            next_indices = np.argmax(probs, axis=-1, keepdims=True)\n",
    "\n",
    "        input_ids = np.concatenate([input_ids, next_indices], axis=1)\n",
    "    \n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "\n",
    "    return output_completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba is the first game to be released on the Nintendo Switch. It is a side-scrolling platformer that is set in a futuristic world where the player must fight against the evil forces of the Mamba.\n",
      "\n",
      "The game is set in a futuristic world where the player must fight against the evil forces of the Mamba. The game is set in a futuristic world where the player must fight against the evil forces of the Mamba.\n",
      "\n",
      "The game is set in a futuristic world where the player must fight against the evil forces of the Mamba. The game is set in a futuristic world where the player must fight\n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'Mamba is the', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: Hi!\n",
      "Sally: Hi!\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John\n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'John: Hi!\\nSally:', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'The meaning of life is ', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'def reverse_string(', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S5Again",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
