{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shida/opt/anaconda3/envs/jax/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/shida/opt/anaconda3/envs/jax/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from model import Mamba, ModelArgs\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# One of:\n",
    "#     'state-spaces/mamba-2.8b-slimpj'\n",
    "#     'state-spaces/mamba-2.8b'\n",
    "#     'state-spaces/mamba-1.4b'\n",
    "#     'state-spaces/mamba-790m'\n",
    "#     'state-spaces/mamba-370m'\n",
    "#     'state-spaces/mamba-130m'\n",
    "pretrained_model_name = 'state-spaces/mamba-370m'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')\n",
    "model, params = Mamba.from_pretrained(pretrained_model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "\n",
    "def jax_generate(model,\n",
    "                 params, \n",
    "                 tokenizer,\n",
    "                 prompt: str,\n",
    "                 n_tokens_to_gen: int = 50,\n",
    "                 sample: bool = True,\n",
    "                 top_k: int = 40,\n",
    "                 rng = jax.random.PRNGKey(7),\n",
    "                 ):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids # In pytorch format\n",
    "    input_ids = np.array(input_ids.numpy()) # In jax format\n",
    "\n",
    "    for token_n in range(n_tokens_to_gen):\n",
    "        indices_to_input = input_ids\n",
    "        next_token_logits = model.apply(params, indices_to_input)[:, -1]\n",
    "\n",
    "        probs = jax.nn.softmax(next_token_logits, axis=-1)\n",
    "\n",
    "        if top_k is not None:\n",
    "            (values, indices) = jax.lax.top_k(probs, k=top_k)\n",
    "            mask = probs < np.expand_dims(values[:, -1], axis=1)\n",
    "            probs = np.where(mask, 0.0, probs)\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "        if sample:\n",
    "            # TODO, might not be 100% correct. \n",
    "            rng, subrng = jax.random.split(rng)\n",
    "            next_indices = jax.random.categorical(subrng, jax.nn.log_softmax(probs), 1, shape=probs.shape[:-1]+(1,))\n",
    "        else:\n",
    "            next_indices = np.argmax(probs, axis=-1, keepdims=True)\n",
    "\n",
    "        input_ids = np.concatenate([input_ids, next_indices], axis=1)\n",
    "    \n",
    "    output_completions = [tokenizer.decode(output.tolist()) for output in input_ids][0]\n",
    "\n",
    "    return output_completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba is the first game to be released on the Nintendo Switch. It is a side-scrolling platformer that is set in a futuristic world where the player must fight against the evil forces of the Mamba.\n",
      "\n",
      "The game is set in a fut\n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'Mamba is the', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John: Hi!\n",
      "Sally: Hi!\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John: I'm John.\n",
      "Sally: I'm Sally.\n",
      "John:\n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'John: Hi!\\nSally:', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is \n",
      "to live in the present moment\n",
      "and to be grateful for what you have.\n",
      "And that's what I'm going to do.\n",
      "I'm going to be grateful for what I have.\n",
      "And I'm going to be grateful for the\n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'The meaning of life is ', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def reverse_string(self, string):\n",
      "        \"\"\"\n",
      "        Return the reverse of the string.\n",
      "\n",
      "        :param string: The string to reverse.\n",
      "        :return: The reversed string.\n",
      "        \"\"\"\n",
      "        return self.reverse(string)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(jax_generate(model, params, tokenizer, 'def reverse_string(', sample=sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S5Again",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
